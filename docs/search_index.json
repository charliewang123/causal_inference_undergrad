[["index.html", "Welcome Course Description Instructor Teaching Assistants Course Logistics Required Materials Learning Objectives Upon successful completion of this course, students will be able to: Tools Useful Links", " Welcome Welcome to the course website for The Science of Why: Causal Inference for Public Health. This course introduces the foundations of causal inference in public health and medical sciences, with an emphasis on distinguishing between association and causation in real-world research. Course Description In this course, students will: Explore foundational concepts such as counterfactuals, causal estimands, and identification strategies. Learn how to critically evaluate causal claims in public health literature. Understand and apply experimental and observational study designs, causal diagrams (DAGs), and bias adjustment methods. Develop practical skills through R-based tutorials and case studies. This course is ideal for undergraduates interested in public health, epidemiology, biostatistics, or social science research. Instructor Falco J. Bargagli-Stoffi Assistant Professor Department of Biostatistics UCLA Fielding School of Public Health falco@ucla.edu Office hours: By appointment. (Book via the scheduling link on this website.) Teaching Assistants TBD — will be announced on the course website. Course Logistics Offered: Fall Term Meetings: Lecture (3 hours), Discussion (1 hour) — in-person unless otherwise announced Assignments: Posted on the course website, due before 8 PM on specified dates Final Project: Group presentation + written report during finals week Required Materials Primary Textbook: Hernán MA, Robins JM. (2023) Causal Inference: What If Free PDF available here Secondary (Recommended) Texts: - Rosenbaum PR. Causal Inference. MIT Press. - Pearl J., Mackenzie D. The Book of Why. Basic Books. Supplementary Readings: Will be shared throughout the course. Learning Objectives Syllabus This course introduces students to the foundations of causal inference in public health and medical sciences, with a strong emphasis on the difference between association and causation. Students will learn to critically evaluate causal claims, understand causal diagrams (DAGs), and assess study design choices in both randomized and observational studies. We will explore how causal effects are identified and estimated, how to detect and adjust for biases (like confounding and selection bias), and how to use critical thinking tools when reviewing public health research. Students will also be introduced to concepts like effect modification, interaction, and systems thinking through real-world applications. Upon successful completion of this course, students will be able to: Communicate public health findings and causal claims in written and oral forms Evaluate causal claims in academic and public health literature Design and assess both randomized trials and observational studies Construct and analyze causal diagrams (DAGs) for identifying sources of bias Apply concepts of effect modification, interaction, and confounding Interpret findings within the context of public health policy and practice Work independently and collaboratively to assess causal research Tools This course will make use of: - R and RStudio - Interactive R tutorials and guided analysis - GitHub for accessing materials and submitting assignments Useful Links UCLA Center for Accessible Education UCLA Equity, Diversity, and Inclusion FSPH EDI Initiative "],["setup.html", "Setup Installing and Using Required Packages Loading Packages Difference Between install.packages() and library() Session Information Why include this? Base R version (simple)", " Setup Installing and Using Required Packages Throughout this tutorial, we’ll use a few essential R packages to manipulate data, run models, and create plots. Below are the core packages, what they do, and how to install them. Packages we’ll use: ggplot2 – For plotting (e.g., scatterplots, regression lines) dplyr – For data wrangling (filtering, mutating, summarizing, etc.) gridExtra – To combine multiple plots into one figure stats – Comes with base R and used for regression (lm()) pacman – Simplifies package management in R broom (optional) – Makes model summaries easier to work with # install.packages(c(&quot;ggplot2&quot;, &quot;dplyr&quot;, &quot;gridExtra&quot;, &quot;pacman&quot;, &quot;broom&quot;)) Loading Packages library(ggplot2) library(dplyr) library(gridExtra) # Optional if using tidy model outputs: # library(broom) Difference Between install.packages() and library() install.packages(“dplyr”) downloads and installs the package — you only need to do this once per computer. library(dplyr) loads the package into your R session — you need to run this each time you use it. Session Information It’s always good practice to include your session info at the end of your analysis. This gives a snapshot of: Your R version and system details All the packages that were loaded The versions of those packages This is especially useful when: - You’re debugging errors - You’re submitting assignments - You’re collaborating with others Why include this? Sometimes code behaves differently depending on the version of a package or even the version of R itself. Including your session info makes your work reproducible and easier to troubleshoot. Base R version (simple) This function comes with R and gives you basic session details. sessionInfo() ## R version 4.5.0 (2025-04-11) ## Platform: aarch64-apple-darwin20 ## Running under: macOS Sequoia 15.1 ## ## Matrix products: default ## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib; LAPACK version 3.12.1 ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## time zone: America/Los_Angeles ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] dagitty_0.3-4 gridExtra_2.3 dplyr_1.1.4 ggplot2_3.5.2 ## ## loaded via a namespace (and not attached): ## [1] Matrix_1.7-3 gtable_0.3.6 jsonlite_2.0.0 compiler_4.5.0 Rcpp_1.0.14 tidyselect_1.2.1 ## [7] jquerylib_0.1.4 splines_4.5.0 scales_1.4.0 boot_1.3-31 yaml_2.3.10 fastmap_1.2.0 ## [13] lattice_0.22-7 R6_2.6.1 labeling_0.4.3 generics_0.1.3 curl_6.2.2 knitr_1.50 ## [19] MASS_7.3-65 tibble_3.2.1 bookdown_0.43 bslib_0.9.0 pillar_1.10.2 RColorBrewer_1.1-3 ## [25] rlang_1.1.6 V8_6.0.3 cachem_1.1.0 xfun_0.52 sass_0.4.10 cli_3.6.5 ## [31] withr_3.0.2 magrittr_2.0.3 mgcv_1.9-3 digest_0.6.37 grid_4.5.0 rstudioapi_0.17.1 ## [37] lifecycle_1.0.4 nlme_3.1-168 vctrs_0.6.5 evaluate_1.0.3 glue_1.8.0 farver_2.1.2 ## [43] rmarkdown_2.29 tools_4.5.0 pkgconfig_2.0.3 htmltools_0.5.8.1 "],["foundations-of-causal-thinking-in-public-health.html", "1 Foundations of Causal Thinking in Public Health Class materials Textbook reading Supplementary reading Topics covered 1.1 Association vs. Causation 1.2 Introduction to Counterfactuals and Potential Outcomes 1.3 Causal Estimands and Identification", " 1 Foundations of Causal Thinking in Public Health Class materials Slides: Module 1 Recording: Module 1, Part 1.1 Recording: Module 1, Part 2.1 Recording: Module 1, Part 2.2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 1–2 Supplementary reading Pearl, J. and Mackenzie, D. (2018) The Book of Why: The New Science of Cause and Effect. Basic Books. Selected public health news articles (provided on the course site). Topics covered Association vs. Causation Introduction to Counterfactuals and Potential Outcomes Causal Estimands and Identification Critical reading exercise: analyzing causal claims in public health news 1.1 Association vs. Causation Association refers to a statistical relationship where two variables move together, but one doesn’t necessarily cause the other. For instance, ice cream sales and drowning incidents both rise in the summer, not because one causes the other, but because they share a third factor: temperature. In contrast, causation implies a direct cause-and-effect relationship, where changing one variable leads to changes in another. Establishing causation requires rigorous methods, such as randomized controlled trials, to rule out confounding factors. Simpson’s Paradox occurs when a trend appears in separate groups but reverses when the data are combined. This paradox is driven by confounding variables—unaccounted factors that influence both the treatment and the outcome. It illustrates how aggregated data can be misleading and emphasizes the importance of analyzing relationships within subgroups to avoid drawing incorrect conclusions. To demonstrate this paradox, I simulated a study comparing two pneumonia treatments across 2,000 trials. Treatment A was mostly given to mild cases, while Treatment B was given to severe cases. When data were analyzed without considering severity, Treatment A seemed more effective. However, when stratified by severity, Treatment B consistently showed lower death rates in both mild and severe groups. This was visualized through two plots: one showing the misleading overall trend, and another stratified by severity revealing the true relationship. A regression model with an interaction term confirmed that treatment effectiveness depends on disease severity, exemplifying Simpson’s Paradox. library(ggplot2) library(dplyr) n &lt;- 2050 severity &lt;- rep(c(&quot;Mild&quot;, &quot;Severe&quot;), times = c(1450, 600)) treatment &lt;- c(rep(&quot;Treatment A&quot;, 1400), rep(&quot;Treatment B&quot;, 50), rep(&quot;Treatment A&quot;, 100), rep(&quot;Treatment B&quot;, 500)) outcome &lt;- c(rbinom(1400, 1, 0.15), # Mild + A (15% death rate) rbinom(50, 1, 0.10), # Mild + B (10% death rate) rbinom(100, 1, 0.30), # Severe + A (30% death rate) rbinom(500, 1, 0.20)) # Severe + B (20% death rate) df &lt;- data.frame( Severity = severity, Treatment = treatment, Outcome = outcome ) death_counts &lt;- tapply(df$Outcome, list(df$Severity, df$Treatment), sum) table_counts &lt;- table(df$Severity, df$Treatment) death_rates &lt;- round(death_counts / table_counts, 3) overall_a &lt;- sum(df$Outcome[df$Treatment == &quot;Treatment A&quot;]) / sum(df$Treatment == &quot;Treatment A&quot;) overall_b &lt;- sum(df$Outcome[df$Treatment == &quot;Treatment B&quot;]) / sum(df$Treatment == &quot;Treatment B&quot;) print(&quot;Death rates by severity and treatment:&quot;) ## [1] &quot;Death rates by severity and treatment:&quot; print(death_rates) ## Treatment A Treatment B ## Mild 0.116 0.080 ## Severe 0.310 0.188 cat(&quot;Overall death rate (Treatment A):&quot;, round(overall_a, 3), &quot;\\n&quot;) ## Overall death rate (Treatment A): 0.129 cat(&quot;Overall death rate (Treatment B):&quot;, round(overall_b, 3), &quot;\\n&quot;) ## Overall death rate (Treatment B): 0.178 suppressWarnings({ overall_plot_data &lt;- data.frame( X_Pos = rep(c(1, 2), each = n), Death_rate = c(rep(overall_a, n), rep(overall_b, n)), Treatment = rep(c(&quot;Treatment A&quot;, &quot;Treatment B&quot;), each = n) ) p1 &lt;- ggplot(overall_plot_data, aes(x = X_Pos, y = Death_rate, color = Treatment)) + geom_point(alpha = 0.1, position = position_jitter(width = 0.05), show.legend = FALSE) + geom_segment(aes(x = 1, xend = 2, y = overall_a, yend = overall_b), color = &quot;black&quot;, size = 1) + scale_x_continuous(breaks = c(1, 2), labels = c(&quot;Treatment A&quot;, &quot;Treatment B&quot;)) + scale_color_manual(values = c(&quot;Treatment A&quot; = &quot;red&quot;, &quot;Treatment B&quot; = &quot;blue&quot;)) + labs(title = &quot;Overall Trend (Simpson&#39;s Paradox)&quot;, x = &quot;&quot;, y = &quot;Risk of Death&quot;) print(p1) }) # Calculate death rates for each severity and treatment rate11 &lt;- df %&gt;% filter(Severity == &quot;Mild&quot;, Treatment == &quot;Treatment A&quot;) %&gt;% pull(Outcome) rate12 &lt;- df %&gt;% filter(Severity == &quot;Mild&quot;, Treatment == &quot;Treatment B&quot;) %&gt;% pull(Outcome) rate21 &lt;- df %&gt;% filter(Severity == &quot;Severe&quot;, Treatment == &quot;Treatment A&quot;) %&gt;% pull(Outcome) rate22 &lt;- df %&gt;% filter(Severity == &quot;Severe&quot;, Treatment == &quot;Treatment B&quot;) %&gt;% pull(Outcome) # Prepare the data for plotting data_by_severity &lt;- data.frame( X_Pos = rep(1:4, each = n), Death_rate = c(rate11, rate12, rate21, rate22), Group = rep(c(&quot;Mild - A&quot;, &quot;Mild - B&quot;, &quot;Severe - A&quot;, &quot;Severe - B&quot;), each = n), Severity = rep(c(&quot;Mild&quot;, &quot;Mild&quot;, &quot;Severe&quot;, &quot;Severe&quot;), each = n) ) # Create the plot with proper jittering and smooth lines p2 &lt;- ggplot(data_by_severity, aes(x = X_Pos, y = Death_rate, color = Group)) + geom_point(alpha = 0.1, position = position_jitter(width = 0.1, height = 0.05), show.legend = FALSE) + # Jitter both horizontally and vertically geom_smooth(data = subset(data_by_severity, Severity == &quot;Mild&quot;), method = &quot;lm&quot;, se = FALSE, color = &quot;black&quot;, aes(group = Severity)) + geom_smooth(data = subset(data_by_severity, Severity == &quot;Severe&quot;), method = &quot;lm&quot;, se = FALSE, color = &quot;black&quot;, aes(group = Severity)) + scale_x_continuous(breaks = 1:4, labels = c(&quot;Mild - A&quot;, &quot;Mild - B&quot;, &quot;Severe - A&quot;, &quot;Severe - B&quot;)) + scale_color_manual(values = c(&quot;Mild - A&quot; = &quot;red&quot;, &quot;Mild - B&quot; = &quot;blue&quot;, &quot;Severe - A&quot; = &quot;darkred&quot;, &quot;Severe - B&quot; = &quot;darkblue&quot;)) + labs(title = &quot;Risk by Severity (Mild vs. Severe)&quot;, x = &quot;&quot;, y = &quot;Risk of Death&quot;) + theme_minimal() + guides(color = &quot;none&quot;) # Removing the legend for clarity print(p2) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; Step 4: Fit Regression Model to Test for Interaction Fitted a linear model to estimate how treatment and severity affect death risk Graphed if there’s an interaction between them regression_data &lt;- data.frame( Death_rate = c(rate11, rate12, rate21, rate22), Treatment = rep(c(0, 1, 0, 1), each = n), Severity = rep(c(0, 0, 1, 1), each = n) ) regression_data$Interaction &lt;- regression_data$Treatment * regression_data$Severity model &lt;- lm(Death_rate ~ Treatment + Severity + Interaction, data = regression_data) summary(model) ## ## Call: ## lm(formula = Death_rate ~ Treatment + Severity + Interaction, ## data = regression_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.142 -0.142 -0.142 -0.142 0.858 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.420e-01 7.710e-03 18.41 &lt;2e-16 *** ## Treatment -1.104e-15 1.090e-02 0.00 1 ## Severity -1.108e-15 1.090e-02 0.00 1 ## Interaction 9.569e-16 1.542e-02 0.00 1 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3491 on 8196 degrees of freedom ## Multiple R-squared: 1.907e-29, Adjusted R-squared: -0.000366 ## F-statistic: 5.209e-26 on 3 and 8196 DF, p-value: 1 1.2 Introduction to Counterfactuals and Potential Outcomes At the heart of causal inference lies a simple yet powerful idea: counterfactuals — what would have happened if something else had occurred. To formalize this, the Potential Outcomes Framework defines two outcomes for each individual: Y(1): The outcome if the individual receives the treatment Y(0): The outcome if the individual does not receive the treatment The causal effect for an individual is the difference: τi = Yi(1) − Yi(0) But here’s the catch: we can never observe both outcomes for the same person. This is known as the Fundamental Problem of Causal Inference. We only observe the outcome under the condition that actually occurred — everything else is unobserved, or counterfactual. As shown in the Simpson’s Paradox example above, failing to account for confounding variables can lead to conclusions that completely misrepresent the true causal effect. When we simply compare outcomes between treated and untreated groups without considering differences in their underlying characteristics (like disease severity), we risk attributing differences to the treatment that are actually due to selection bias. By thinking in terms of potential outcomes — what would have happened under treatment vs. no treatment — we can see how causal claims require more than just association. This framework makes clear that understanding the data-generating process is critical, and it motivates the need for methods that can uncover hidden structure in the data. While the average treatment effect (ATE) helps summarize the overall impact of a treatment, it often masks important variation across individuals. In practice, not everyone responds to treatment the same way — some benefit more than others, and some may even be harmed. This brings us to the concept of the Individual Treatment Effect (ITE), which asks: what was the treatment effect for this specific person? Although we can never observe both potential outcomes for a single individual, we can use modeling techniques to estimate ITEs and explore treatment effect heterogeneity. The following example demonstrates how this was done using simulated data. Individual Treatment Effect (ITE) In causal inference, the Individual Treatment Effect (ITE) measures how much one specific patient benefits from a treatment. ITE focuses on personalized benefits - how much an intervention would change the outcome for each person at the same time. The formula for the ITE is Yi(1) - Yi(0), where Yi(1) is the outcome if the person receives the treatment while Yi(0) is the outcome if the person does not receive the treatment. A fundamental problem in causal inference is that we can never observe both Yi(1) and Yi(0) for the same person, because each person either receives the treatment or does not, meaning one of the outcomes is missing. This is known as the fundamental problem of causal inference, and because of this, we use statistical methodologies and machine learning techniques to estimate ITE. To do this, I simulated healthcare data. Simulating the Patient Data Simulated 2,000 individuals, each with baseline characteristics: age, BMI, and cholesterol. Treatment assignment is based on a model where older individuals with higher cholesterol are more likely to receive treatment. Generated two potential outcomes for each individual: Y(0) (if untreated) and Y(1) (if treated). The observed outcome depends on whether each person actually received treatment or not. Calculated the true individual treatment effect (ITE) as the difference between Y(1) and Y(0). # Simulate data for 2,000 individuals n &lt;- 2000 # Generate baseline covariates (age, BMI, cholesterol) age &lt;- rnorm(n, mean = 50, sd = 10) # Normally distributed age centered around 50 bmi &lt;- rnorm(n, mean = 25, sd = 4) # BMI centered around 25 cholesterol &lt;- rnorm(n, mean = 200, sd = 30) # Cholesterol centered around 200 # Simulate treatment assignment using logistic regression: # Older individuals with higher cholesterol are more likely to be treated treatment &lt;- rbinom(n, 1, plogis(0.05 * age + 0.01 * cholesterol - 2)) # Simulate potential outcome without treatment (Y(0)) # Outcome depends on age, BMI, and cholesterol plus random noise y_0 &lt;- 140 - 0.5 * age + 0.3 * bmi + 0.2 * cholesterol + rnorm(n, sd = 5) # Simulate potential outcome with treatment (Y(1)) # Treatment effect varies with age and cholesterol and adds its own noise y_1 &lt;- y_0 - (40 + 1.0 * age - 0.3 * cholesterol) + rnorm(n, sd = 1.5) # Observed outcome: if treated, observe Y(1); otherwise, observe Y(0) y &lt;- ifelse(treatment == 1, y_1, y_0) # Calculate the true Individual Treatment Effect (ITE) true_ite &lt;- y_1 - y_0 # Difference between potential outcomes for each person # Combine into a data frame for analysis data &lt;- data.frame( age, bmi, cholesterol, treatment, y, # observed outcome true_ite # the true (unobserved) individual causal effect ) # Preview the first few rows of the dataset head(data) ## age bmi cholesterol treatment y true_ite ## 1 59.09336 27.59360 197.5519 1 109.89198 -38.47166 ## 2 50.12370 18.73318 189.3397 1 127.55453 -31.34194 ## 3 52.15306 20.49743 219.8410 1 126.55925 -27.68562 ## 4 53.94252 20.24831 144.5960 1 99.59211 -52.15800 ## 5 36.91065 24.44705 205.2673 1 152.28678 -14.90954 ## 6 43.74325 32.36804 156.7873 1 122.31924 -36.30009 Next, I estimated treatment effects using regression. Since I can’t observe both Y(0) and Y(1) for any individual, I used separate regressions for treatment and control groups. I used the models to predict counter factual outcomes for all patients and to compute the estimated ITE as the difference between Y(1) and Y(0). Estimate Treatment Effects Using Regression control_model &lt;- lm(y ~ age + bmi + cholesterol, data = data, subset = (treatment == 0)) treatment_model &lt;- lm(y ~ age + bmi + cholesterol, data = data, subset = (treatment == 1)) data$y0_hat &lt;- predict(control_model, newdata = data) data$y1_hat &lt;- predict(treatment_model, newdata = data) data$ite_estimate &lt;- data$y1_hat - data$y0_hat head(data[c(&quot;ite_estimate&quot;, &quot;y0_hat&quot;, &quot;y1_hat&quot;)]) ## ite_estimate y0_hat y1_hat ## 1 -39.17579 157.4554 118.27956 ## 2 -33.58145 158.3584 124.77697 ## 3 -26.50701 163.9585 137.45146 ## 4 -50.26463 147.5878 97.32317 ## 5 -15.35841 169.7268 154.36835 ## 6 -35.48908 158.1105 122.62139 Now, I plotted the true ITE vs the estimated ITE. Here, each point is a patient, and the red dashed line represents the ideal estimation. If the point fits well with the line, then the model is accurate. Visualizing the Estimated ITE # library(ggplot2) ggplot(data, aes(x = true_ite, y = ite_estimate)) + geom_point(alpha = 0.5) + geom_abline(slope = 1, intercept = 0, col = &quot;red&quot;, linetype = &quot;dashed&quot;) + labs(title = &quot;Estimated ITE vs True ITE (Blood Pressure Reduction)&quot;, x = &quot;True ITE&quot;, y = &quot;Estimated ITE&quot;) Visualizing the Esimated ITE Without Looking at Confounding Estimated average potential outcomes without adjusting for covariates. Filled in predicted values based on group averages. y0_hat_simple &lt;- mean(data$y[data$treatment == 0]) y1_hat_simple &lt;- mean(data$y[data$treatment == 1]) data$y0_hat_simple &lt;- ifelse(data$treatment == 1, y0_hat_simple, data$y) data$y1_hat_simple &lt;- ifelse(data$treatment == 0, y1_hat_simple, data$y) data$ite_estimate_simple &lt;- data$y1_hat_simple - data$y0_hat_simple ggplot(data, aes(x = true_ite, y = ite_estimate_simple)) + geom_point(alpha = 0.5) + geom_abline(slope = 1, intercept = 0, col = &quot;red&quot;, linetype = &quot;dashed&quot;) + labs(title = &quot;Estimated ITE vs True ITE (No Confounder Adjustment)&quot;, x = &quot;True ITE&quot;, y = &quot;Estimated ITE (Unadjusted)&quot;) + theme_minimal() Here are the top 10 patients who benefited the most from the treatment. This helps me identify patients who are most likely to benefit, as well as focus on individuals with high predicted response. Patients Who Benefit Most top_beneficiaries &lt;- data[order(data$ite_estimate), ][1:10, ] top_beneficiaries[, c(&quot;age&quot;, &quot;bmi&quot;, &quot;cholesterol&quot;, &quot;ite_estimate&quot;)] ## age bmi cholesterol ite_estimate ## 1165 80.33482 25.13123 133.4620 -79.06324 ## 616 66.41704 27.40510 113.6013 -70.92476 ## 1987 76.36464 28.77438 149.1510 -70.21952 ## 326 76.10334 22.30859 150.9641 -70.05255 ## 1537 80.42694 28.70560 169.4516 -68.30319 ## 931 79.44158 23.93230 169.1237 -67.88533 ## 522 66.13431 25.17372 125.8576 -67.28147 ## 1785 70.99804 24.95190 145.0172 -66.50295 ## 1813 61.58360 28.65182 116.3598 -65.23527 ## 1204 73.14319 21.83492 161.0429 -64.23728 1.3 Causal Estimands and Identification Causal estimands are the quantities we aim to estimate to understand the effect of a treatment or intervention. The most common estimands include: - Average Treatment Effect (ATE): Measures the average difference in outcomes if everyone received the treatment versus if no one did. - Average Treatment Effect on the Treated (ATT): Measures the effect of treatment for those who actually received the treatment. - Average Treatment Effect on the Controls (ATC): Measures the effect for those who did not receive the treatment. - Conditional Average Treatment Effect (CATE): Measures the treatment effect for subgroups defined by observed characteristics (e.g., older vs. younger patients). Identification is the process of linking a causal estimand (like ATE) to observable data. Without valid identification, any estimates we produce may be biased or incorrect. One major challenge in causal inference is that we can never observe both potential outcomes for the same person — only the outcome under the actual treatment they received. This is the Fundamental Problem of Causal Inference. To overcome this, we make assumptions (like unconfoundedness or selection on observables) and use statistical models to estimate the missing potential outcome. Conditional Average Treatment Effect (CATE) The Conditional Average Treatment Effect (CATE) represents the expected treatment effect for a specific subgroup of patients with a particular characteristic. Unlike the Average Treatment Effect (ATE), which measures the treatment’s effect on the entire population, CATE understands that the population is not homogeneous and conditions on certain variables (e.g. age, BMI, cholesterol). CATE can be described as E[Y(1) - Y(0) | X], where X is the observed characteristics. This allows researchers to see which groups benefit more or less from a treatment, which can in-turn affect future decisions. For example, in clinical trials, a drug may work more effectively for older patients than younger ones. Another example would be a job program working more effectively on people with college degrees than people without college degrees. Estimating CATE allows business owners, researchers, and policymakers to make effective decisions that optimize outcomes for all groups. To estimate CATE from observational data, I fitted separate predictive models for the treated and control groups and then computed the expected difference in outcomes for different subgroups. I estimated the CATE for age groups by splitting the data into younger individuals (age &lt; 40 years) and older individuals (age &gt;= 40 years) and then computing the average Individual Treatment Effect (ITE) within each group. Computing the Conditional Average Treatment Effect (CATE) for Age Groups threshold &lt;- 50 cate_young &lt;- mean(data$ite_estimate[data$age &lt; threshold]) cate_old &lt;- mean(data$ite_estimate[data$age &gt;= threshold]) Finally, I stored and display the CATE results. Store and Display CATE Results results &lt;- data.frame( age_group = c(&quot;&lt; 40 years&quot;, &quot;&gt;= 40 years&quot;), cate_estimate = c(cate_young, cate_old) ) print(results) ## age_group cate_estimate ## 1 &lt; 40 years -21.65116 ## 2 &gt;= 40 years -37.82581 From the table, we can see that the CATE is more negative for older individuals, meaning that the treatment appears to be more effective for people older than 40. Because the CATE for younger individuals is lower, this means that the treatment is less effective for young people. This shows that age influences the effectiveness of the treatment. Here is a visualization of the CATE estimates. Visualization of the CATE Effects Based on Age cate_young_se &lt;- sd(data$ite_estimate[data$age &lt; threshold]) / sqrt(sum(data$age &lt; threshold)) cate_old_se &lt;- sd(data$ite_estimate[data$age &gt;= threshold]) / sqrt(sum(data$age &gt;= threshold)) results &lt;- data.frame( age_group = c(&quot;&lt; 50 years&quot;, &quot;&gt;= 50 years&quot;), cate_estimate = c(cate_young, cate_old), lower = c(cate_young - 1.96 * cate_young_se, cate_old - 1.96 * cate_old_se), upper = c(cate_young + 1.96 * cate_young_se, cate_old + 1.96 * cate_old_se) ) ggplot(results, aes(y = age_group, x = cate_estimate)) + geom_point(color = &quot;red&quot;, size = 2) + geom_errorbar(aes(xmin = lower, xmax = upper), width = 0.4, color = &quot;blue&quot;) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;) + labs(title = &quot;Subgroup Analysis of Treatment Effect&quot;, x = &quot;Conditional Average Treatment Effect (CATE)&quot;, y = &quot;Age Group&quot;) + theme_minimal() Average Treatment Effect (ATE) The Average Treatment Effect (ATE) represents the impact of a treatment or exposure across an entire population. It is the difference between the average outcome with treatment and the average outcome without treatment. ATE is expressed as E[Y(1)] - E[Y(0)] where Y(1) is the potential outcome if treated and Y(0) is the potential outcome if not treated. ATE measures the treatment’s effectiveness but it also assumes homogeneity between the two groups, meaning it doesn’t account for differences within the groups. In real-life, treatment effects can be mitigated or enhanced because of characteristics like age, income or gender, which is why the Conditional Average Treatment Effect (CATE) are used to study heterogeneity, or differences between the treated and non-treated groups. Computing the Average Treatment Effect ate &lt;- mean(data$ite_estimate) print(paste(&quot;The Average Treatment Effect (ATE) is&quot;, round(ate, 2))) ## [1] &quot;The Average Treatment Effect (ATE) is -29.81&quot; Here is a visualization for the Average Treatment Effect (ATE). I created a simple bar chart comparing the health outcome for treated and non-treated individuals. The bar chart shows a higher blood pressure for non-treated individuals and a lower blood pressure for treated individuals, showing the positive impacts of the treatment The height difference between the two bars represents the ATE. ATE Visualization control_se &lt;- sd(data$ite_estimate[data$treatment == 0]) / sqrt(sum(data$treatment == 0)) treated_se &lt;- sd(data$ite_estimate[data$treatment == 1]) / sqrt(sum(data$treatment == 1)) control_mean &lt;- mean(data$y0_hat[data$treatment == 0]) treated_mean &lt;- mean(data$y1_hat[data$treatment == 1]) results &lt;- data.frame( group = c(&quot;Control (Y0)&quot;, &quot;Treated (Y1)&quot;), ate_estimate = c(control_mean, treated_mean), lower = c(control_mean - 1.96 * control_se, treated_mean - 1.96 * treated_se), upper = c(control_mean + 1.96 * control_se, treated_mean + 1.96 * treated_se) ) ggplot(results, aes(y = group, x = ate_estimate)) + geom_point(color = &quot;red&quot;, size = 2) + geom_errorbar(aes(xmin = lower, xmax = upper), width = 0.4, color = &quot;blue&quot;) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;) + labs(title = &quot;Estimated Average Treatment Effect&quot;, x = &quot;Estimated Average Treatment Effect&quot;, y = &quot;Control vs. Treated&quot;) + theme_minimal() Average Treatment Effect on the Treated (ATT) The Average Treatment Effect on the Treated (ATT) measures the impact of a treatment or exposure only among people who received it. Unlike the Average Treatment Effect (ATE), which looks at the effect across the entire population, ATT focuses on those that were actually exposed or treated. ATT is expressed as E[Y(1) - Y(0)|T=1] where Y(1) is the potential outcome with treatment and Y(0) is the potential outcome without treatment, and T=1 indicates only those people who were actually exposed or treated. ATT helps determine whether the intervention is effective or not for the treated population. It is particularly useful for analyzing policies or medical treatments when the treatment is not randomly assigned. In the case of looking at treatments and blood pressure changes, ATT helps answer the question: How much does the treatment impact the blood pressure of individuals who were actually treated? Average Treatment Effect on the Treated (ATT) Calculated att &lt;- mean(data$ite_estimate[data$treatment == 1]) print(paste(&quot;The Average Treatment Effect on the Treated (ATT) is&quot;, round(att, 2))) ## [1] &quot;The Average Treatment Effect on the Treated (ATT) is -30.01&quot; Average Treatment Effect on the Control (ATC) The Average Treatment Effect on the Control (ATC) measures the effect of a treatment on individuals who were not actually exposed to the treatment or exposure. Unlike the Average Treatment Effect on the Treated (ATT), which estimates the impact for those who received the treatment, ATC explains how the control group would have been affected if they have been treated. ATC is expressed as E[Y(1) - Y(0)|T=0] where Y(1) represents the potential outcome with treatment, Y(0) represents the potential outcome without treatment, and T=0 represents people who did not receive treatment. ATC is useful when analyzing policies or medical treatments to understand how untreated individuals would have been affected by the intervention. In this scenario, ATC answers the question: How much would the treatment have affected individuals who were not exposed to it? To calculate ATC, I took the average treatment effect of the subset of the population that were not exposed to the treatment. If ATC is negative, it means that the treatment would have harmed the control group if they were exposed. By comparing the ATT and the ATC, it helps us determine if the treatment has differential effects across subgroups. Average Treatment Effect on the Control (ATC) Calculated atc &lt;- mean(data$ite_estimate[data$treatment == 0]) print(paste(&quot;The Average Treatment Effect on the Control (ATC) is&quot;, round(atc, 2))) ## [1] &quot;The Average Treatment Effect on the Control (ATC) is -27.6&quot; Now, I’ve created a visualization comparing how the treatment effect differs for treated and control groups. ATT vs. ATC Visualization att_se &lt;- sd(data$ite_estimate[data$treatment == 1]) / sqrt(sum(data$treatment == 1)) atc_se &lt;- sd(data$ite_estimate[data$treatment == 0]) / sqrt(sum(data$treatment == 0)) results &lt;- data.frame( group = c(&quot;ATT (Treated)&quot;, &quot;ATC (Control)&quot;), estimate = c(att, atc), lower = c(att - 1.96 * att_se, atc - 1.96 * atc_se), upper = c(att + 1.96 * att_se, atc + 1.96 * atc_se) ) ggplot(results, aes(y = group, x = estimate)) + geom_point(color = &quot;red&quot;, size = 2) + geom_errorbar(aes(xmin = lower, xmax = upper), width = 0.4, color = &quot;blue&quot;) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;) + labs(title = &quot;Estimated ATT vs. ATC&quot;, x = &quot;Estimated Treatment Effect&quot;, y = &quot;Group&quot;) + theme_minimal() Since the ATT is more negative than to ATC, it indicates that the treatment is more effective on the treated group. One potential explanation is that age and cholesterol are confounding variables. There are more older people and people with higher cholesterol levels in the treated group than the non-treated, meaning that this could skew the results as the groups are not homogenous. "],["randomized-control-trials.html", "2 Randomized Control Trials Class materials Textbook reading Supplementary reading Topics covered 2.1 Randomized controlled trials: the gold standard 2.2 Basic Experimental Design Principles 2.3 Limitations of RCTs in Public Health Contexts 2.4 Common Threats to Internal and External Validity", " 2 Randomized Control Trials Class materials Slides: Module 2 Recording: Module 2, Part 1 Recording: Module 2, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 3–4 Supplementary reading Pearl, J. (2009). Causal inference in statistics: An overview. Statistics Surveys, 3, 96–146.  Selected DAG examples from public health studies (provided in class) Topics covered Randomized controlled trials: the gold standard Basic experimental design principles Limitations of RCTs in public health contexts Common threats to internal and external validity Critical reading exercise: evaluating a published RCT 2.1 Randomized controlled trials: the gold standard Randomized Controlled Trials (RCTs) are widely considered the gold standard in causal inference because they offer the most rigorous way to establish whether a treatment or intervention truly causes an outcome. The key feature that sets RCTs apart is randomization: participants are randomly assigned to treatment or control groups, which ensures that—on average—all other characteristics (like age, health status, and behaviors) are equally distributed across groups. This process breaks any systematic link between confounders and treatment assignment, making the groups exchangeable and allowing us to interpret differences in outcomes as causal effects of the treatment. Because of this design, RCTs eliminate the need to adjust for confounders or worry about selection bias in the same way observational studies do. They provide clean estimates of the average treatment effect (ATE) with high internal validity, especially when they are well-executed and have minimal loss to follow-up. However, RCTs are not without limitations. They can be expensive, time-consuming, and sometimes unethical or impractical—such as when withholding treatment would cause harm. Despite these limitations, RCTs serve as the benchmark against which other study designs are compared, and understanding their strengths helps us interpret both experimental and non-experimental evidence more critically. In this simulation, I will recreate a simple randomized controlled trial (RCT) to estimate the effect of a new treatment on patient outcomes. I randomly assigned 2,000 individuals to either a treatment or control group and simulate their outcomes based on their assignment. Because of randomization, I expected the two groups to be similar in baseline characteristics, allowing for an unbiased estimate of the treatment effect. After simulating the data, I estimated the Average Treatment Effect (ATE) by comparing mean outcomes between the groups, and visualized the distribution of outcomes to confirm the treatment impact. Simulated Baseline Data and Treatment Assignment # pacman::p_load(&quot;dplyr&quot;, &quot;ggplot2&quot;) n &lt;- 2000 age &lt;- rnorm(n, 50, 10) treatment &lt;- rbinom(n, 1, 0.5) y_0 &lt;- 100 - 0.3 * age + rnorm(n, sd = 10) y_1 &lt;- y_0 - 10 + rnorm(n, sd = 5) y &lt;- ifelse(treatment == 1, y_1, y_0) rct_data &lt;- data.frame( age = age, treatment = treatment, y = y ) head(rct_data) ## age treatment y ## 1 63.56339 0 109.05249 ## 2 43.33933 1 75.11519 ## 3 56.13526 0 77.75397 ## 4 54.65999 1 66.55734 ## 5 52.73924 0 85.38610 ## 6 42.51490 0 90.67985 Estimated the Average Treatment Effect (ATE) ate_estimate &lt;- rct_data |&gt; group_by(treatment) |&gt; summarize(mean_outcome = mean(y)) |&gt; summarize(ATE = diff(mean_outcome)) |&gt; pull(ATE) paste(&quot;Estimated ATE: &quot;, round(ate_estimate, 2)) ## [1] &quot;Estimated ATE: -9.38&quot; Visualization of the Outcome Distributions ggplot(rct_data, aes(x = as.factor(treatment), y = y, fill = as.factor(treatment))) + geom_boxplot(alpha = 0.7) + labs( title = &quot;Distribution of Outcomes by Treatment Group&quot;, x = &quot;Treatment: Control (0) vs Treated (1)&quot;, y = &quot;Outcome&quot; ) + scale_fill_manual(values = c(&quot;red&quot;, &quot;blue&quot;)) + theme_minimal() 2.2 Basic Experimental Design Principles At the heart of randomized controlled trials (RCTs) lies experimental design, the set of strategies we use to ensure that the comparison between groups is fair, unbiased, and informative. Good experimental design ensures that any differences in outcomes between the treatment and control groups can be confidently attributed to the treatment itself, and not to other confounding variables. Three basic principles guide experimental design: randomization, control, and replication. Randomization is the process of randomly assigning participants to treatment or control groups. This prevents systematic differences between groups at baseline and ensures that confounding variables (both known and unknown) are evenly distributed. Control involves creating a baseline group (the control group) that does not receive the treatment, allowing for a meaningful comparison. Replication refers to having enough participants so that random fluctuations even out, providing more precise and reliable estimates of the treatment effect. In our previous simulation, we applied these principles by randomly assigning 2,000 individuals to either a treatment or control group, simulating outcomes based only on treatment status and baseline characteristics (age). Because we randomized treatment assignment, we can be confident that any observed difference in outcomes is causally attributable to the treatment, not to age differences, baseline health, or other confounders. Without randomization, we would have needed to control for these factors. This simulation highlights why randomization is considered the gold standard for causal inference. 2.3 Limitations of RCTs in Public Health Contexts While randomized controlled trials (RCTs) are the gold standard for establishing causality, they are not without important limitations when applied to public health settings. First, ethical constraints often limit what interventions can be randomly assigned. For example, it would be unethical to randomly assign people to smoke or not smoke in order to study lung cancer. Public health research must often rely on observational studies where randomization is impossible. Second, feasibility and cost can be major barriers. Conducting large-scale RCTs can require enormous resources, making them impractical for studying widespread or long-term public health interventions like school nutrition programs or climate effects on health. Generalizability is another concern. Many RCTs are conducted in tightly controlled environments with selective populations, meaning their results may not apply to broader, more diverse real-world populations. In our earlier simulation, randomization guaranteed an unbiased estimate of the average treatment effect (ATE) within the study population. However, in real-world public health research, participants who volunteer for RCTs may differ from the general public, and interventions may behave differently outside of controlled settings. This highlights the importance of thinking critically about how experimental results translate into everyday public health practice. 2.4 Common Threats to Internal and External Validity When evaluating any causal study, it’s critical to think about validity, whether the results are accurate (internal validity) and whether they generalize beyond the study setting (external validity). Internal validity refers to whether the observed effect truly reflects the causal effect within the study population. Threats to internal validity include: Confounding, if randomization fails or is compromised (e.g., noncompliance with assigned treatment). Selection bias, if participants drop out or are lost to follow-up in a way that is related to both treatment and outcome. Measurement error, if outcomes or treatments are recorded inaccurately. External validity, on the other hand, concerns whether results from the study can be generalized to other settings, populations, or time periods. Threats to external validity include: Non-representative samples, such as RCTs recruiting only highly motivated individuals who differ from the general population. Intervention differences, where the way a treatment is delivered in a trial setting doesn’t match how it would be implemented in the real world. Contextual factors, such as cultural, economic, or healthcare system differences that make the same intervention work differently elsewhere. In the earlier RCT simulation, we achieved excellent internal validity because treatment was randomized perfectly and outcomes were cleanly measured. However, that simulation assumes an idealized setting; in real public health research, threats to validity often creep in, and careful design and critical thinking are needed to recognize and minimize them. "],["observational-studies.html", "3 Observational Studies Class materials Textbook reading Supplementary reading Topics covered 3.1 The challenge of confounding in public health and medical research 3.2 Exchangeability, positivity, and consistency 3.3 Effect Identification in Observational Studies", " 3 Observational Studies Class materials Slides: Module 3 Recording: Module 3, Part 1 Recording: Module 3, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 5–6 Supplementary reading Greenland, S. (2003). Quantifying biases in causal models: classical confounding vs collider-stratification bias. Epidemiology, 14(3), 300–306.  Additional DAG exercises provided in class Topics covered The challenge of confounding in public health and medical research Exchangeability, positivity, and consistency Effect identification in observational studies Critical reading exercise: evaluating a published observational study 3.1 The challenge of confounding in public health and medical research Confounding is a major challenge in public health and medical research because it can create misleading associations between exposures and outcomes. A confounder is a third variable that is associated with both the exposure and the outcome, potentially distorting the true causal relationship. For example, if we observe that people who carry lighters tend to have higher rates of lung cancer, we might wrongly conclude that carrying a lighter causes cancer. In reality, smoking is the confounding variable: smokers are more likely to carry lighters and also more likely to develop lung cancer. Without properly adjusting for confounders, studies risk producing biased estimates, leading to incorrect conclusions about risk factors, treatments, or interventions. Addressing confounding is crucial but not always straightforward. Methods such as stratification, multivariable regression, propensity score matching, and randomized controlled trials (RCTs) are commonly used to try to adjust for or eliminate confounding effects. However, identifying all relevant confounders can be difficult, especially when dealing with observational data where randomization is not possible. Unmeasured or unknown confounders remain a constant threat to validity. Therefore, careful study design, domain knowledge, and sensitivity analyses are essential to minimize the impact of confounding and ensure more reliable and actionable public health research findings. Example Setup Let’s say we want to study the effect of Exercise (X) on Heart Health (Y), but there’s a Genetic Factor (Z) that causes both Exercise and Heart Health. In this case, Z is a confounder, and we should adjust for it. n &lt;- 2000 genetics &lt;- rnorm(n) exercise &lt;- 0.6 * genetics + rnorm(n) heart_health &lt;- 0.8 * exercise + 0.5 * genetics + rnorm(n) df &lt;- data.frame(heart_health, exercise, genetics) model_naive &lt;- lm(heart_health ~ exercise, data = df) summary(model_naive)$coefficients[&quot;exercise&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 1.0483173 0.0213858 49.0193083 0.0000000 model_adjusted &lt;- lm(heart_health ~ exercise + genetics, data = df) summary(model_adjusted)$coefficients[&quot;exercise&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 8.181965e-01 2.309963e-02 3.542033e+01 1.139372e-213 # library(ggplot2) naive_estimate &lt;- summary(model_naive)$coefficients[&quot;exercise&quot;, &quot;Estimate&quot;] adjusted_estimate &lt;- summary(model_adjusted)$coefficients[&quot;exercise&quot;, &quot;Estimate&quot;] estimates &lt;- data.frame( Model = c(&quot;Naive&quot;, &quot;Adjusted&quot;), Estimate = c(naive_estimate, adjusted_estimate) ) ggplot(estimates, aes(x = Model, y = Estimate, fill = Model)) + geom_col(width = 0.5) + labs(title = &quot;Comparison of Naive vs Adjusted Estimates&quot;, y = &quot;Estimated Effect of Exercise&quot;, x = &quot;&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) In this simulation, we model a situation where Genetics (Z) is a confounder that influences both Exercise (X) and Heart Health (Y). The naive model, which regresses Heart Health on Exercise without adjusting for Genetics, gives a biased estimate of the effect of Exercise. This happens because part of the observed association is actually due to Genetics, not Exercise itself. When we adjust for Genetics in the second model, the estimate of Exercise’s effect becomes more accurate, isolating its true relationship with Heart Health. This example highlights how failing to account for confounding can lead researchers to overstate or misinterpret causal effects in public health and medical studies. 3.2 Exchangeability, positivity, and consistency In causal inference, particularly when analyzing observational data, three critical assumptions must hold for estimates to reflect true causal relationships: exchangeability, positivity, and consistency. These assumptions ensure that the comparisons we make between groups are valid and that the effects we estimate correspond to real-world interventions. Without them, causal conclusions can be biased or entirely invalid. Exchangeability means that after adjusting for confounders, the treatment and comparison groups are similar in all relevant ways except for the exposure itself. Positivity means that every individual has a nonzero probability of receiving each level of the exposure, regardless of their confounder values. Consistency means that the observed outcome under the actual exposure is the same as the potential outcome we are trying to measure for that exposure level. In our previous simulation studying exercise and heart health, adjusting for genetics aimed to restore exchangeability by balancing genetic differences between individuals with different exercise levels. Positivity was satisfied because individuals at all levels of genetics still varied in how much they exercised. Consistency was assumed because the way we measured exercise and heart health accurately reflected the underlying causal relationship. Together, these assumptions allowed us to interpret the adjusted effect of exercise on heart health as a causal effect. 3.3 Effect Identification in Observational Studies In observational studies, identifying causal effects is challenging because researchers do not control exposure assignments. Unlike randomized controlled trials, individuals self-select into exposure groups, leading to potential confounding. Effect identification requires careful strategies to mimic the conditions of randomization and ensure that observed associations reflect true causal relationships rather than biases from confounding or selection. Confounding control: Adjust for confounders through methods like regression, stratification, matching, or weighting to approximate randomization. Assumptions: Rely on assumptions like exchangeability, positivity, and consistency to justify causal interpretation. Sensitivity analysis: Explore how robust the estimated effect is to potential unmeasured confounding. In our simulation of exercise and heart health, we identified the causal effect of exercise by adjusting for the confounding effect of genetics. Without randomization, genetics could have biased the relationship between exercise and health outcomes. By including genetics as a covariate in our model, we attempted to recreate the conditions needed for causal identification in an observational setting, relying on the assumptions of exchangeability, positivity, and consistency to interpret the adjusted exercise effect as causal. "],["randomized-controlled-trials-rcts-and-quasi-experiments.html", "4 Randomized Controlled Trials (RCTs) and Quasi-Experiments Class materials Textbook reading Supplementary reading Topics covered 4.1 Effect Modification and Adjustment Methods 4.2 Identifying Interaction 4.3 Effect Modification vs Interaction", " 4 Randomized Controlled Trials (RCTs) and Quasi-Experiments Class materials Slides: Module 4 Recording: Module 4, Part 1 Recording: Module 4, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 7–8 Supplementary reading Freedman, D. A. (2008). On types of scientific inquiry: The role of RCTs in health policy. Journal of the Royal Statistical Society: Series A, 171(2), 359–385.  Examples of quasi-experiments from public health and education Topics covered Effect modification and adjustment methods Identifying interaction Effect modification vs interaction Critical reading exercise: evaluating effect modification and interaction in studies 4.1 Effect Modification and Adjustment Methods Effect modification occurs when the effect of an exposure on an outcome differs depending on the level of another variable. Unlike confounding, which biases the estimated effect, effect modification reflects a real variation in the causal effect across different subgroups. Recognizing effect modification is important because it can reveal that a treatment or exposure is beneficial for some groups but not for others. Adjustment methods like stratification or including interaction terms in regression models help detect and describe effect modification rather than “control” it away. Adjustment methods typically aim to control for confounding, but they can also be used to detect effect modification when interaction terms are included. When effect modification is present, a single summary effect estimate (like an overall average) can be misleading. Instead, researchers often report subgroup-specific effects. Careful modeling and interpretation are necessary to distinguish between true effect modification and residual confounding. Simulation to Demonstrate Effect Modification We simulate a case where exercise improves heart health, but the effect of exercise is stronger for people with a good diet. That is, diet modifies the effect of exercise on heart health. n &lt;- 2000 diet &lt;- rnorm(n) exercise &lt;- rnorm(n) heart_health &lt;- (1 + 2 * diet) * exercise + 3 * diet + rnorm(n) df &lt;- data.frame(heart_health, exercise, diet) naive_model &lt;- lm(heart_health ~ exercise + diet, data = df) interaction_model &lt;- lm(heart_health ~ exercise * diet, data = df) summary(naive_model) ## ## Call: ## lm(formula = heart_health ~ exercise + diet, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -10.6400 -1.1282 -0.0554 1.1150 12.9062 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.05420 0.05136 -1.055 0.291 ## exercise 0.95675 0.05176 18.483 &lt;2e-16 *** ## diet 3.00926 0.05149 58.447 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.297 on 1997 degrees of freedom ## Multiple R-squared: 0.6505, Adjusted R-squared: 0.6501 ## F-statistic: 1858 on 2 and 1997 DF, p-value: &lt; 2.2e-16 summary(interaction_model) ## ## Call: ## lm(formula = heart_health ~ exercise * diet, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.8464 -0.6797 -0.0190 0.6684 3.1513 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.01440 0.02202 -0.654 0.513 ## exercise 0.98423 0.02219 44.348 &lt;2e-16 *** ## diet 2.97111 0.02208 134.586 &lt;2e-16 *** ## exercise:diet 2.04730 0.02174 94.182 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9846 on 1996 degrees of freedom ## Multiple R-squared: 0.9358, Adjusted R-squared: 0.9357 ## F-statistic: 9697 on 3 and 1996 DF, p-value: &lt; 2.2e-16 Plot showing the differences between people with high genetics and low genetics # library(ggplot2) # library(dplyr) df_grouped &lt;- df |&gt; mutate(diet_group = ifelse(diet &gt; median(diet), &quot;Good Diet&quot;, &quot;Bad Diet&quot;)) ggplot(df_grouped, aes(x = exercise, y = heart_health, color = diet_group)) + geom_point(alpha = 0.5) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + labs(title = &quot;Effect Modification: Exercise and Diet&quot;, subtitle = &quot;Separate Regression Lines for Good and Bad Diet&quot;, x = &quot;Exercise Level&quot;, y = &quot;Heart Health&quot;, color = &quot;Diet Group&quot;) + theme_minimal() ## `geom_smooth()` using formula = &#39;y ~ x&#39; In this simulation, the benefit of exercise on heart health is stronger for individuals with better diet. When we run a naive model without an interaction term, we miss this important difference and incorrectly estimate a single average effect. When we include an interaction term between exercise and diet, we correctly capture that the effect of exercise varies across diet (healthy to unhealthy). The plot shows how heart health depends not just on exercise but also on how diet modifies the strength of that effect — illustrating why detecting and modeling effect modification is crucial in public health research. 4.2 Identifying Interaction Identifying interaction is crucial when studying causal relationships because it tells us whether the effect of an exposure on an outcome varies across levels of another variable. An interaction exists when the impact of one variable depends on the value of another, meaning the combined effect is not simply additive. Rather than being a source of bias like confounding, interaction reveals real differences in how subgroups respond to exposures or treatments. Detecting interaction helps researchers understand for whom and under what conditions an intervention works best, allowing for more tailored public health strategies and clinical recommendations. In our previous simulation with exercise and diet, interaction was present because the benefit of exercise on heart health was greater for individuals with a better diet. By fitting a model with an interaction term between exercise and diet, we were able to identify and quantify this effect modification. Without testing for interaction, we would have incorrectly assumed that exercise has the same benefit for everyone, masking important subgroup differences. Identifying interaction thus helps uncover nuanced causal relationships that average treatment effects alone may miss. 4.3 Effect Modification vs Interaction Effect modification and interaction are closely related concepts, but they serve slightly different purposes in causal analysis. Effect modification refers to a real difference in the causal effect of an exposure on an outcome across levels of another variable. It describes a biological or contextual phenomenon where an exposure has varying impacts depending on a modifier, such as a treatment working better for younger patients than older ones. In contrast, interaction is a modeling term: it refers to the inclusion of a product term (like exposure × modifier) in a statistical model to detect and estimate effect modification. In essence, effect modification is a feature of reality, while interaction is how we model and identify it in data. In our previous simulation with exercise and diet, the true underlying process involved effect modification: the benefit of exercise on heart health was greater for individuals with better diet. To uncover this, we included an interaction term between exercise and diet (exercise * diet) in our regression model. Without including the interaction, the model would have incorrectly assumed a constant effect of exercise across all diets (healthy to unhealthy). This distinction highlights why researchers must carefully model interactions when they suspect effect modification is present — otherwise, important subgroup differences in treatment effects can be hidden by overly simple models. "],["introduction-to-causal-diagrams.html", "5 Introduction to Causal Diagrams Class materials Textbook reading Supplementary reading Topics covered 5.1 Basic principles of directed acyclic graphs (DAGs) 5.2 Common Causal Structures in Public Health 5.3 Using DAGs to introduce and understand selection bias", " 5 Introduction to Causal Diagrams Class materials Slides: Module 5 Recording: Module 5, Part 1 Recording: Module 5, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 9–10 Supplementary reading Rosenbaum, P.R., &amp; Rubin, D.B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41–55. Examples from public health studies involving confounding adjustment Topics covered Basic principles of directed acyclic graphs (DAGs) Common causal structures in public health Using DAGs to introduce and understand selection bias Application: drawing DAGs for public health scenarios 5.1 Basic principles of directed acyclic graphs (DAGs) Directed acyclic graphs (DAGs) are powerful tools in causal inference that visually represent assumptions about how variables are related. In a DAG, nodes represent variables, and arrows (directed edges) represent causal influences from one variable to another. DAGs are acyclic, meaning you cannot return to the same variable by following a sequence of arrows — this prevents feedback loops. The key strength of DAGs lies in their ability to clarify causal pathways, distinguish between confounding and mediation, and identify the variables we need to control for to estimate causal effects accurately. By encoding assumptions explicitly, DAGs help researchers determine whether observed associations reflect true causal relationships or are biased by omitted variables or incorrect conditioning. In our simulation, we use a DAG to represent a common public health structure involving diet, exercise, and heart health. Diet is a confounder: it directly influences both how much people exercise and their overall heart health. If we ignore diet when estimating the effect of exercise on heart health, we risk attributing diet’s effect to exercise — leading to confounding bias. The DAG for this scenario includes arrows from diet to both exercise and heart health, and from exercise to heart health. We also introduce selection bias by conditioning on individuals with moderate-to-high exercise levels. In DAG terms, this is equivalent to conditioning on a collider (exercise), which can open a non-causal backdoor path and bias our results. Modeling this setup with a DAG allows us to see clearly that to obtain an unbiased estimate of the causal effect of exercise, we must adjust for diet and avoid conditioning on colliders like selection into the sample. # library(ggplot2) # library(dplyr) # library(ggdag) # library(dagitty) n &lt;- 2000 diet &lt;- rnorm(n) exercise &lt;- 2 * diet + rnorm(n) heart_health &lt;- 3 * exercise + 4 * diet + rnorm(n) dag &lt;- dagitty(&quot;dag { diet -&gt; exercise diet -&gt; heart_health exercise -&gt; heart_health }&quot;) plot(dag) ## Plot coordinates for graph not supplied! Generating coordinates, see ?coordinates for how to set your own. adjustmentSets(dag, exposure = &quot;exercise&quot;, outcome = &quot;heart_health&quot;) ## { diet } 5.2 Common Causal Structures in Public Health In public health research, understanding the causal relationships between variables is essential for identifying risk factors, designing interventions, and making policy decisions. Common causal structures include confounding, mediation, and collider bias, each of which influences how we interpret observed associations. A confounder is a variable that affects both the exposure and the outcome, potentially biasing the estimated effect if not properly adjusted for. A mediator lies on the causal pathway between exposure and outcome, helping to explain how the exposure exerts its effect. A collider, on the other hand, is influenced by two variables, and conditioning on it can introduce spurious associations. Identifying these structures often requires drawing directed acyclic graphs (DAGs) to map out assumptions and determine which variables to adjust for when estimating causal effects. In our simulation, we modeled a classic confounding structure, where diet influences both exercise and heart health. This mirrors real-world public health situations where health behaviors and biological outcomes are shaped by shared underlying factors like nutrition, socioeconomic status, or genetics. If we were to estimate the effect of exercise on heart health without adjusting for diet, we would risk attributing some of diet’s impact to exercise — a classic confounding problem. By visualizing the relationships using a DAG and including diet as a covariate in our regression model, we can block the backdoor path and isolate the true causal effect of exercise. This illustrates how understanding and modeling common causal structures is critical to producing valid and meaningful results in public health research. 5.3 Using DAGs to introduce and understand selection bias Selection bias occurs when the group of individuals included in a study is systematically different from the target population in a way that distorts the relationship between exposure and outcome. This can happen when inclusion into the study depends on variables that are related to either the exposure, the outcome, or both. Selection bias becomes especially problematic when researchers condition on a collider — a variable that is influenced by two or more variables in the causal model — because doing so can open non-causal paths and create spurious associations. In practical terms, this means that even if there is no causal relationship between an exposure and an outcome, conditioning on a collider can make it look like there is one, or it can distort the strength of a real effect. In our simulation, we introduced selection bias by only including individuals with moderate to high diet scores. Since diet is a confounder that affects both exercise and heart health, restricting our analysis to individuals with good diets creates a biased sample — one that no longer reflects the full population variation in diet. This conditioning on diet essentially blocks our ability to observe the full confounding relationship and can make the estimated effect of exercise on heart health appear stronger, weaker, or even reverse. By simulating this, we demonstrate how selection bias — even when introduced through something seemingly harmless like focusing on healthier individuals — can lead to incorrect causal conclusions if not properly accounted for. df &lt;- data.frame(diet, exercise, heart_health) df_selected &lt;- df |&gt; filter(diet &gt; 0) model_naive &lt;- lm(heart_health ~ exercise, data = df_selected) model_adjusted &lt;- lm(heart_health ~ exercise + diet, data = df_selected) summary(model_naive)$coefficients[&quot;exercise&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 4.18217932 0.03735574 111.95548022 0.00000000 summary(model_adjusted)$coefficients[&quot;exercise&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 2.95159462 0.03238224 91.14855171 0.00000000 selection_bias_dag &lt;- dagitty(&quot;dag { diet -&gt; exercise diet -&gt; heart_health exercise -&gt; heart_health diet -&gt; selection }&quot;) plot(selection_bias_dag) ## Plot coordinates for graph not supplied! Generating coordinates, see ?coordinates for how to set your own. "],["effect-modification-and-interaction.html", "6 Effect Modification and Interaction Class materials Textbook reading Supplementary reading Topics Covered 6.1 The Structure of Confounding 6.2 How to Adjust for Confounding 6.3 The Form of Selection Bias 6.4 How to Adjust for Selection Bias", " 6 Effect Modification and Interaction Class materials Slides: Module 6 Recording: Module 6, Part 1 Recording: Module 6, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapter 11 Supplementary reading Knol, M. J., &amp; VanderWeele, T. J. (2012). Recommendations for presenting analyses of effect modification and interaction. International Journal of Epidemiology, 41(2), 514–520. Real-world public health examples of effect modification Topics Covered The structure of confounding How to adjust for confounding The form of selection bias How to adjust for selection bias Critical reading exercise: sources of confounding and selection bias in public health 6.1 The Structure of Confounding Confounding occurs when an external variable influences both the exposure and the outcome, making it difficult to determine whether the observed association is truly causal. This third variable — the confounder — can create a misleading impression that the exposure causes the outcome, when in fact, the association may be driven entirely or partially by the confounder. The key structural feature of confounding is that the confounder must be related to both the exposure and the outcome. To obtain an accurate estimate of the exposure’s causal effect, researchers must adjust for confounding variables using methods like stratification, regression, or matching. In our simulation, age acts as a confounder because it affects both smoking behavior and lung cancer risk. Older individuals are more likely to smoke and also more likely to develop lung cancer, which can make smoking appear more harmful (or even less harmful) than it actually is if age isn’t taken into account. The naive model, which includes only smoking, produces a biased estimate because it doesn’t separate the effect of smoking from the effect of age. The adjusted model includes both smoking and age and provides a more accurate estimate of smoking’s effect by accounting for this confounding influence. This example highlights how confounding can distort findings and why controlling for related background variables is essential in observational research. n &lt;- 2000 age &lt;- rnorm(2000, mean = 50, sd = 10) smoking &lt;- 2 * age + rnorm(n) lung_cancer &lt;- 3 * smoking + 4 * age + rnorm(n) genetic_marker &lt;- rbinom(n, 1, prob = plogis(0.01 * smoking - 1)) df &lt;- data.frame( Age = age, Smoking = smoking, Lung_Cancer = lung_cancer, Genetic_Marker = genetic_marker ) model_naive &lt;- lm(lung_cancer ~ smoking, data = df) model_adjusted &lt;- lm(lung_cancer ~ smoking + age, data = df) coef_naive &lt;- summary(model_naive)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_adjusted &lt;- summary(model_adjusted)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_naive ## [1] 4.997379 coef_adjusted ## [1] 3.044864 6.2 How to Adjust for Confounding Adjusting for confounding is essential when estimating causal effects from observational data. Since confounders are variables that influence both the exposure and the outcome, failing to account for them can lead to biased and misleading conclusions. One of the most common ways to adjust for confounders is through multiple regression, where confounders are included as covariates in the model. Other methods include stratification, where analyses are performed within levels of the confounder, and matching, where exposed and unexposed individuals are paired based on similar values of the confounding variable. These approaches aim to isolate the effect of the exposure by holding confounders constant, thereby mimicking the balance achieved in randomized experiments. In our simulation, we demonstrated adjustment for confounding using regression. The variable age was a confounder because it influenced both smoking and lung cancer. When we fit a naive model that only included smoking, the effect estimate was biased because it reflected both smoking’s and age’s contributions to lung cancer. By including age in the model as an additional predictor, we were able to adjust for its influence. This adjustment allowed us to estimate the effect of smoking on lung cancer more accurately, as if age were held constant. This simple regression approach illustrates a key principle in observational research: if you can measure the confounder and include it in your analysis, you can often remove its biasing effect and get closer to the true causal relationship. 6.3 The Form of Selection Bias Selection bias arises when the individuals included in a study are not representative of the target population due to a systematic filtering process. This filtering — whether intentional (like restricting analysis to a subgroup) or unintentional (like only including those who responded to a survey) — can distort the observed relationship between an exposure and an outcome. The core structure of selection bias involves inclusion in the study being related to variables that are also related to the exposure or the outcome. This means the analysis is performed on a biased subset of the population, which can create spurious associations or mask real ones, even when a true causal effect exists. In our simulation, we introduced selection bias by restricting the dataset to individuals with moderate to good diets. Because diet is related to both exercise and heart health, this restriction caused the analyzed sample to no longer reflect the full population. As a result, the apparent relationship between exercise and heart health in the filtered sample may differ from the true relationship in the full population. This demonstrates the form of selection bias: by conditioning on a variable that is related to both the exposure and the outcome (in this case, indirectly through diet), we introduced distortion into the analysis. This example shows how selection criteria — even seemingly benign ones — can alter causal interpretations if they create unbalanced or artificially restricted datasets. df_biased &lt;- df |&gt; filter(genetic_marker == 1) model_naive &lt;- lm(lung_cancer ~ smoking, data = df_biased) model_adjusted &lt;- lm(lung_cancer ~ smoking + age, data = df_biased) coef_naive &lt;- summary(model_naive)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_adjusted &lt;- summary(model_adjusted)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_naive ## [1] 4.997379 coef_adjusted ## [1] 3.044864 6.4 How to Adjust for Selection Bias Adjusting for selection bias is more challenging than adjusting for confounding, because selection bias arises when the sample being analyzed is not representative of the target population due to a systematic inclusion process. This often happens when selection into the dataset depends on variables related to both the exposure and the outcome, introducing a spurious association that distorts causal estimates. Unlike confounding, which can often be handled by conditioning on measured variables, selection bias may require more complex strategies such as inverse probability weighting (IPW), sensitivity analysis, or explicitly modeling the selection mechanism. The key to adjusting for selection bias is understanding why and how certain individuals are excluded or included in the analysis — and then incorporating that information to correct the bias. In the simulation above, we introduced selection bias by filtering the dataset to include only individuals who smoked more than the average level. Because smoking is influenced by age and also affects lung cancer, conditioning on it distorts the relationship between age and lung cancer. While the naive model estimated the effect of smoking without accounting for age, the adjusted model included age as a covariate and produced a more accurate effect estimate. However, unlike confounding, adjusting for a covariate like age doesn’t always fully correct for selection bias — especially when selection is based on a collider or a downstream consequence of both exposure and outcome. This illustrates that although standard regression adjustment can help, it may not completely remove bias introduced through selective inclusion, reinforcing the need to carefully consider how and why individuals are included in an analysis. "],["measurement-missing-data-and-selection-bias.html", "7 Measurement, Missing Data, and Selection Bias Class materials Textbook reading Supplementary reading Topics covered 7.1 Measurement Bias 7.2 Non-Causal Diagrams 7.3 Publication Bias and P-Hacking 7.4 Over- and Mis-Interpretation of Statistical Analyses", " 7 Measurement, Missing Data, and Selection Bias Class materials Slides: Module 7 Recording: Module 7, Part 1 Recording: Module 7, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 12–13 Supplementary reading Groenwold, R. H., et al. (2012). Dealing with missing outcome data in randomized trials and observational studies. American Journal of Epidemiology, 175(3), 210–217. Examples of misclassification and selection bias in public health research Topics covered Measurement bias Non-causal diagrams Publication bias and p-hacking Over- and mis-interpretation of statistical analyses Application: developing a checklist for critical reading of causal claims 7.1 Measurement Bias Measurement bias occurs when the method used to collect data leads to systematic errors in the values recorded for a variable. This can happen when an exposure, outcome, or confounder is misclassified or inaccurately measured in a way that consistently overstates or understates the true value. Measurement bias is problematic because it can distort observed associations and lead to incorrect conclusions about the relationships between variables. Unlike random measurement error, which tends to cancel out over large samples, measurement bias introduces consistent errors that don’t disappear with more data. It can arise from faulty instruments, poorly worded survey questions, or inconsistent data collection procedures, and it often goes unnoticed unless explicitly tested for. In public health and medical research, measurement bias can affect both exposure and outcome variables. For example, if smoking behavior is self-reported and individuals tend to underreport how much they smoke, the study will underestimate the true relationship between smoking and lung cancer. Similarly, if age is recorded in broad categories rather than precise years, it can limit the ability to adjust accurately for confounding. Even adjusting for confounders may not correct measurement bias if those confounders are also measured with error. This makes it critical to use reliable, validated measurement tools and to account for potential misclassification during analysis, especially in observational studies where data quality may vary widely. This simulation demonstrates measurement bias by comparing the estimated effect of smoking on lung cancer using the true smoking values versus mismeasured (underreported) smoking. The model using mismeasured smoking underestimates the true effect, showing how systematic error in recording an exposure can bias causal estimates toward zero. n &lt;- 2000 age &lt;- rnorm(n, mean = 50, sd = 10) true_smoking &lt;- 2 * age + rnorm(n) # no age to isolate measurement bias in smoking lung_cancer &lt;- 3 * true_smoking + rnorm(n) measured_smoking &lt;- true_smoking - rnorm(n, mean = 1, sd = 0.5) true_model &lt;- lm(lung_cancer ~ true_smoking + age) biased_model &lt;- lm(lung_cancer ~ measured_smoking + age) true_coef &lt;- summary(true_model)$coefficients[&quot;true_smoking&quot;, &quot;Estimate&quot;] biased_coef &lt;- summary(biased_model)$coefficients[&quot;measured_smoking&quot;, &quot;Estimate&quot;] true_coef ## [1] 3.022831 biased_coef ## [1] 2.381477 7.2 Non-Causal Diagrams Non-causal diagrams represent associations between variables that do not imply direct cause-and-effect relationships. These diagrams are useful for illustrating statistical relationships that arise from shared causes, correlations due to bias, or measurement artifacts. In non-causal diagrams, arrows may still indicate directional influence, but they are used to reflect associations or data-generating processes, not claims about interventions. Unlike causal diagrams, which are designed to identify and estimate the effects of manipulating one variable on another, non-causal diagrams help clarify patterns in the data without asserting that changing one variable will necessarily change another. In the context of our simulation, we can use a non-causal diagram to represent the observed association between age and lung cancer without assuming a direct causal relationship. While age and lung cancer may be strongly correlated — older individuals tend to have higher cancer risk — this relationship does not imply that age causes lung cancer in an interventional sense. Instead, age may be acting as a proxy for other underlying factors like cumulative exposure to smoking or environmental risks. A non-causal diagram helps us visualize this statistical association without attributing it to a direct, manipulable pathway, highlighting that not all observed relationships in data should be interpreted as causal. 7.3 Publication Bias and P-Hacking Publication bias occurs when the likelihood of a study being published depends on the nature or direction of its results — typically favoring studies with statistically significant or “positive” findings. This creates a distorted picture of the evidence in a field, because null or contradictory results are less likely to be seen. P-hacking refers to the practice of manipulating statistical analyses or data collection until a desired (usually statistically significant) result is achieved. This can include selectively reporting outcomes, running many analyses and only publishing those with low p-values, or stopping data collection once a significant result appears. Both practices inflate false-positive rates and undermine the credibility of scientific findings. In the context of the simulation we ran — whether it involves confounding, selection bias, or measurement error — it’s easy to see how p-hacking or publication bias could skew interpretations. For example, imagine rerunning the simulation many times and only reporting the version where the naive model shows a significant effect of smoking on lung cancer (even if the underlying data or causal structure doesn’t support it). Or selectively reporting only the adjusted model that produces a “clean” result while hiding others. These practices can make even a carefully designed simulation appear misleading. The simulation reinforces the idea that statistical significance is not the same as truth, and that transparency in modeling choices and full reporting of results are critical for avoiding biased conclusions. 7.4 Over- and Mis-Interpretation of Statistical Analyses Over-interpretation occurs when researchers draw stronger conclusions from statistical results than the data can justify, while mis-interpretation involves misunderstanding what the results actually mean. A common example is interpreting a statistically significant association as proof of causation, even when the study design or model does not support that claim. Another frequent error is overstating the practical importance of a small effect size or assuming that a non-significant result means “no effect.” These issues are often driven by pressure to produce definitive conclusions, even when the data are limited, noisy, or confounded. Careful interpretation requires understanding the limits of the methods used and being transparent about uncertainty, assumptions, and alternative explanations. In the simulations we’ve conducted — such as estimating the effect of smoking on lung cancer under different types of bias — it’s easy to see how results can be over- or mis-interpreted. For instance, in a model affected by measurement bias or confounding, one might find a statistically significant association between smoking and lung cancer, but incorrectly conclude that the estimated effect size reflects the true causal effect. Alternatively, if the biased model appears significant and the true model does not, someone might misinterpret that as evidence that adjustment “eliminated” the effect, when in fact it corrected for bias. These examples highlight how even simple models can be misunderstood or overstated, and underscore the importance of grounding interpretation in study design, data limitations, and causal reasoning — not just statistical output. "],["from-identification-to-estimation.html", "8 From Identification to Estimation Class materials Textbook reading Supplementary reading Topics covered 8.1 Identification and Estimation", " 8 From Identification to Estimation Class materials Slides: Module 8 Recording: Module 8, Part 1 Recording: Module 8, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapter 14 Supplementary reading VanderWeele, T. J., &amp; Ding, P. (2017). Sensitivity analysis in observational research: introducing the E-value. Annals of Internal Medicine, 167(4), 268–274. Case studies on unmeasured confounding and robustness of findings Topics covered Identification versus estimation Estimation of causal effects Taxonomy of estimation models Critical reading exercise: evaluating identification and estimation in a published study 8.1 Identification and Estimation In causal inference, identification refers to the theoretical question of whether a causal effect can be determined from the observed data and the assumptions encoded in the study design or model. It answers the question: “Can we, in principle, express the causal effect of interest as a function of the observed variables?” Identification depends on assumptions such as exchangeability (no unmeasured confounding), positivity, and consistency, and often involves tools like potential outcomes or directed acyclic graphs (DAGs). If a causal effect is not identifiable, no amount of statistical analysis will yield a valid estimate — because the data alone cannot disentangle the causal effect from bias or confounding. Once identification is established, the next step is estimation, which involves applying statistical methods to calculate the size of the effect using real data. Estimation uses techniques like regression, inverse probability weighting, or matching to quantify the identified causal relationship. In our simulations, for example, once we specify that the causal effect of smoking on lung cancer is identifiable by adjusting for age, we use regression to estimate that effect. If we skip the identification step and go straight to estimation without accounting for confounding or bias, our estimates may be precise — but wrong. Together, identification and estimation form the backbone of credible causal analysis: one ensures that we’re asking the right question, and the other that we’re answering it correctly. This simulation is the same one used in Week 6 and represents an observational study where smoking is not randomized but influenced by age. Age also directly affects lung cancer, making it a confounder that biases the naive estimate of smoking’s effect. By adjusting for age in the regression model, we recover a more accurate estimate of the true causal effect of smoking on lung cancer. This simulation illustrates the concepts of identification and estimation by showing that, without adjusting for the confounder (age), the causal effect of smoking on lung cancer cannot be correctly identified. Once the effect is identified through proper adjustment, it can then be accurately estimated using regression. n &lt;- 2000 age &lt;- rnorm(2000, mean = 50, sd = 10) smoking &lt;- 2 * age + rnorm(n) lung_cancer &lt;- 3 * smoking + 4 * age + rnorm(n) df &lt;- data.frame( Age = age, Smoking = smoking, Lung_Cancer = lung_cancer ) model_naive &lt;- lm(lung_cancer ~ smoking, data = df) model_adjusted &lt;- lm(lung_cancer ~ smoking + age, data = df) coef_naive &lt;- summary(model_naive)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_adjusted &lt;- summary(model_adjusted)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_naive ## [1] 4.995661 coef_adjusted ## [1] 2.973846 "],["systems-thinking-and-policy-translation.html", "9 Systems Thinking and Policy Translation Class materials Textbook reading Supplementary reading Topics covered", " 9 Systems Thinking and Policy Translation Class materials Slides: Module 9 Recording: Module 9, Part 1 Recording: Module 9, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapter 15 Supplementary reading Sterman, J. D. (2006). Learning from evidence in a complex world. American Journal of Public Health, 96(3), 505–514. Examples of systems-level interventions in public health and policy Topics covered Introduction to systems thinking in public health Complex causality and feedback loops Translating causal findings into policy recommendations Ethical and practical challenges of implementation Evaluating impact in dynamic systems "],["final-project-presentations.html", "10 Final Project Presentations Class materials Guidelines Deliverables Topics covered", " 10 Final Project Presentations Class materials Slides: Final Project Overview Recording: Project Presentation Session Guidelines Projects must clearly state a causal question and why it’s relevant to public health. Use DAGs or potential outcomes framework to illustrate assumptions and design. Present evidence from real or simulated data, clearly indicating assumptions and limitations. Address potential biases and whether sensitivity analysis was performed. Be ready to respond to peer and instructor questions. Deliverables Written report (5–8 pages) In-class presentation (8–10 minutes per group) Peer feedback on other presentations Topics covered Synthesis of course concepts in real-world applications Communicating causal findings to a public health audience Critical peer review and constructive feedback Translating methods into actionable insights "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
